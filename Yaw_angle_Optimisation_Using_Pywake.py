# -*- coding: utf-8 -*-
"""tryingpywake.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QbZ4O2Jkx_Tji3LEtTHiqsd3Iu8bIYU1
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pytorch-lightning pandas xarray torchist xskillscore pyyaml zarr

!pip install pywake

try:
    import py_wake
except ModuleNotFoundError:
    !pip install git+https://gitlab.windenergy.dtu.dk/TOPFARM/PyWake.git

import sys
sys.path.append('/content/drive/MyDrive/chaosbench')  # adjust this if your ChaosBench is in a different location

import torch
import yaml
from models.model import S2SBenchmarkModel
from dataset import CSV_ERA5_Dataset
import config

# Load YAML config
config_filepath = '/content/drive/MyDrive/chaosbench/configs/fno_pinn.yaml'
with open(config_filepath, 'r') as file:
    config_yaml = yaml.safe_load(file)

model_args = config_yaml['model_args']
data_args = config_yaml['data_args']

# Load model directly from checkpoint
ckpt_path = '/content/drive/MyDrive/ChaosBench/checkpoints/best_model.ckpt'
model = S2SBenchmarkModel.load_from_checkpoint(
    ckpt_path,
    model_args=model_args,
    data_args=data_args
)
model.eval()

# Dataset and dataloader
train_dataset = CSV_ERA5_Dataset(
    years=data_args['train_years'],
    variables=config.PARAMS,
    pressure_levels=config.PRESSURE_LEVELS,
    is_normalized=True
)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)

# Prediction loop
predictions = []
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
with torch.no_grad():
    for _, inputs, _ in train_loader:
        inputs = inputs.to(device)
        outputs = model(inputs)
        predictions.append(outputs.cpu())

predictions = torch.cat(predictions, dim=0)

import xarray as xr
import numpy as np

climatology = xr.open_zarr('/content/drive/MyDrive/climatology/climatology_era5.zarr')
params = climatology['param'].values
u10_idx, v10_idx = np.where(params == 'u-10')[0][0], np.where(params == 'v-10')[0][0]

mean_u10 = climatology['mean'].values[u10_idx]
sigma_u10 = climatology['sigma'].values[u10_idx]
mean_v10 = climatology['mean'].values[v10_idx]
sigma_v10 = climatology['sigma'].values[v10_idx]

u10 = predictions[:, 0] * sigma_u10 + mean_u10
v10 = predictions[:, 1] * sigma_v10 + mean_v10

wind_speed = torch.sqrt(u10 ** 2 + v10 ** 2)
wind_direction = torch.atan2(v10, u10) * (180 / np.pi) % 360

print(f"Wind speed shape: {wind_speed.shape}")
print(f"Wind direction shape: {wind_direction.shape}")
print("First denorm wind speed sample:\n", wind_speed[0])
print("First denorm wind direction sample:\n", wind_direction[0])

import matplotlib.pyplot as plt

nx, ny, spacing = 10, 8, 560
x = np.arange(nx) * spacing
y = np.arange(ny) * spacing
xx, yy = np.meshgrid(x, y)
turbine_x = torch.tensor(xx.flatten(), dtype=torch.float32)
turbine_y = torch.tensor(yy.flatten(), dtype=torch.float32)
num_turbines = len(turbine_x)

# Horns Rev 1 Layout
plt.scatter(turbine_x, turbine_y)
plt.axis('equal')
plt.title("Horns Rev 1 Layout")
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from py_wake.examples.data.hornsrev1 import V80
from py_wake.literature.gaussian_models import Bastankhah_PorteAgel_2014
from py_wake.superposition_models import SquaredSum
from py_wake.site import UniformSite
from tqdm import tqdm

site = UniformSite(p_wd=[1], ti=0.1)
wake_model = Bastankhah_PorteAgel_2014(site, V80(), k=0.075, superpositionModel=SquaredSum())

features_list, power_list = [], []
for _ in tqdm(range(5000)):
    ws, wd = np.random.uniform(5, 14), np.random.uniform(0, 360)
    yaw = np.random.uniform(-30, 30, num_turbines)
    site.default_wd, site.default_ws = np.array([wd]), np.array([ws])
    sim_res = wake_model(turbine_x.numpy(), turbine_y.numpy(), yaw=yaw)
    total_power = np.sum(sim_res.Power.values) / 1e6

    yaw_t = torch.tensor(yaw, dtype=torch.float32)
    ws_t = torch.full((num_turbines,), ws)
    wd_t = torch.full((num_turbines,), wd)
    feat = torch.stack([yaw_t, ws_t, wd_t, turbine_x, turbine_y], dim=1)

    features_list.append(feat)
    power_list.append(torch.tensor(total_power, dtype=torch.float32))

torch.save({'features': features_list, 'powers': power_list}, 'surrogate_dataset.pt')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

# Surrogate Model
class PowerSurrogateNet(nn.Module):
    def __init__(self, num_turbines, hidden_dim=128):
        super(PowerSurrogateNet, self).__init__()
        self.fc1 = nn.Linear(num_turbines * 5, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.fc3 = nn.Linear(hidden_dim, 1)  # Predict total power

    def forward(self, yaw, ws, wd, turbine_x, turbine_y):
        """
        yaw: [batch_size, num_turbines]
        ws:  [batch_size, 1]
        wd:  [batch_size, 1]
        turbine_x, turbine_y: [num_turbines] (constants)
        """
        batch_size, num_turbines = yaw.shape

        # Repeat turbine layout for batch
        x = turbine_x.unsqueeze(0).repeat(batch_size, 1).to(yaw.device)
        y = turbine_y.unsqueeze(0).repeat(batch_size, 1).to(yaw.device)

        ws_exp = ws.repeat(1, num_turbines)
        wd_exp = wd.repeat(1, num_turbines)

        # Stack all turbine-level inputs
        features = torch.stack([yaw, ws_exp, wd_exp, x, y], dim=2)
        features = features.view(batch_size, -1)

        h = F.relu(self.fc1(features))
        h = F.relu(self.fc2(h))
        power = self.fc3(h)
        return power.squeeze(1)


# Surrogate Dataset Loader
class SurrogateDataset(Dataset):
    def __init__(self, path):
        data = torch.load(path)
        self.features = data['features']
        self.powers = data['powers']

    def __len__(self):
        return len(self.features)

    def __getitem__(self, idx):
        return self.features[idx], self.powers[idx]

# Load dataset
num_turbines = turbine_x.shape[0]
dataset = SurrogateDataset('surrogate_dataset.pt')
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Model and Optimiser
surrogate = PowerSurrogateNet(num_turbines).to(device)
optimizer = torch.optim.Adam(surrogate.parameters(), lr=1e-3)
criterion = nn.MSELoss()

# Training loop
for epoch in range(50):
    surrogate.train()
    total_loss = 0.0
    for feat, power in train_loader:
        feat, power = feat.to(device), power.to(device)

        # Split `feat`: shape [batch_size, num_turbines, 5]
        yaw = feat[:, :, 0]
        ws = feat[:, 0, 1].unsqueeze(1)  # single ws per sample
        wd = feat[:, 0, 2].unsqueeze(1)  # single wd per sample

        # turbine_x and turbine_y are static
        turbine_x_batch = turbine_x.to(device)
        turbine_y_batch = turbine_y.to(device)

        # Forward pass
        pred_power = surrogate(yaw, ws, wd, turbine_x_batch, turbine_y_batch)

        loss = criterion(pred_power, power)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1:02d}: Loss = {total_loss / len(train_loader):.4f}")

!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html

import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool

class TGNYawOptimizer(nn.Module):
    def __init__(self, node_in_dim=4, node_hidden_dim=32, gru_hidden_dim=64, num_turbines=40):
        super(TGNYawOptimizer, self).__init__()

        # GNN Encoder (per timestep)
        self.gnn = GCNConv(node_in_dim, node_hidden_dim)

        # GRU temporal processor (across timesteps)
        self.gru = nn.GRU(node_hidden_dim, gru_hidden_dim, batch_first=True)

        # Output head to predict yaw angles
        self.yaw_head = nn.Sequential(
            nn.Linear(gru_hidden_dim, gru_hidden_dim),
            nn.ReLU(),
            nn.Linear(gru_hidden_dim, num_turbines)
        )

    def forward(self, sequences):
        """
        sequences: list of sequences (batch_size, seq_len) with temporal graphs
        returns: predicted yaw angles per turbine [batch_size, num_turbines]
        """
        batch_size = len(sequences)
        seq_len = len(sequences[0])

        num_turbines = sequences[0][0].x.size(0)

        graph_embeddings = []

        for t in range(seq_len):
            x_t_list, edge_index_list, batch_idx_list = [], [], []

            for b in range(batch_size):
                graph = sequences[b][t]
                x_t_list.append(graph.x)
                edge_index_list.append(graph.edge_index)
                batch_idx_list.append(torch.full((num_turbines,), b, dtype=torch.long, device=graph.x.device))

            x_t = torch.cat(x_t_list, dim=0)
            edge_index = torch.cat([ei + i * num_turbines for i, ei in enumerate(edge_index_list)], dim=1)
            batch_idx = torch.cat(batch_idx_list, dim=0)

            h_t = F.relu(self.gnn(x_t, edge_index))
            graph_h = global_mean_pool(h_t, batch_idx)
            graph_embeddings.append(graph_h.unsqueeze(1))

        sequence = torch.cat(graph_embeddings, dim=1)
        gru_out, _ = self.gru(sequence)
        last_hidden = gru_out[:, -1, :]

        predicted_yaws = self.yaw_head(last_hidden)
        return predicted_yaws

import torch
from torch_geometric.data import Data

def generate_dynamic_dataset(window_size=5):
    graphs = []

    for t in range(45):
        ws = np.mean(wind_speed[t].numpy())
        wd = np.mean(wind_direction[t].numpy())

        node_features = np.stack([
            turbine_x.numpy(), turbine_y.numpy(),
            np.full_like(turbine_x.numpy(), ws),
            np.full_like(turbine_x.numpy(), wd)
        ], axis=1)

        edge_index = torch.combinations(torch.arange(num_turbines), r=2).t().contiguous()
        edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)

        g = Data(
            x=torch.tensor(node_features, dtype=torch.float32),
            edge_index=edge_index,
            timestep=t
        )
        graphs.append(g)

    sequences = []
    for i in range(len(graphs) - window_size):
        seq = graphs[i:i + window_size]
        sequences.append(seq)

    print(f"Created {len(sequences)} temporal graph sequences!")
    return sequences

temporal_sequences = generate_dynamic_dataset(window_size=5)

from torch.utils.data import Dataset, DataLoader as TorchLoader

# Dataset for graph sequences
class TGNDataset(Dataset):
    def __init__(self, sequences):
        self.sequences = sequences

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        return self.sequences[idx]

# Create dataset and loaders
train_sequences = temporal_sequences[:int(0.8 * len(temporal_sequences))]
test_sequences = temporal_sequences[int(0.8 * len(temporal_sequences)):]

train_dataset = TGNDataset(train_sequences)
test_dataset = TGNDataset(test_sequences)

batch_size = 4
train_loader = TorchLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: x)
test_loader = TorchLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)

# TGN
yaw_optimizer = TGNYawOptimizer(
    node_in_dim=4,
    node_hidden_dim=32,
    gru_hidden_dim=64,
    num_turbines=num_turbines
).to(device)

optimizer = torch.optim.AdamW(yaw_optimizer.parameters(), lr=0.001, weight_decay=1e-4)

# Training loop (power maximisation objective)
for epoch in range(50):
    yaw_optimizer.train()
    total_loss = 0.0

    for batch in train_loader:
        optimizer.zero_grad()
        sequences = batch
        pred_yaws = yaw_optimizer(sequences)

        # Get ws & wd from latest timestep graph for each batch
        ws_list, wd_list = [], []
        for i in range(len(pred_yaws)):
            wind_input = sequences[i][-1]
            ws = wind_input.x[0, 2].item()
            wd = wind_input.x[0, 3].item()
            ws_list.append(ws)
            wd_list.append(wd)

        ws_tensor = torch.tensor(ws_list, dtype=torch.float32, device=device).unsqueeze(1)
        wd_tensor = torch.tensor(wd_list, dtype=torch.float32, device=device).unsqueeze(1)

        # Surrogate power prediction
        power_pred = surrogate(pred_yaws, ws_tensor, wd_tensor, turbine_x.to(device), turbine_y.to(device))

        # Loss = negative mean power
        loss = -torch.mean(power_pred)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1:02d}: Train Loss = {total_loss / len(train_loader):.4f} (maximize power)")

torch.save(yaw_optimizer.state_dict(), "tgn_yaw_optimizer.pth")
print("Yaw optimizer trained & saved.")

# Load trained optimiser
yaw_optimizer = TGNYawOptimizer(
    node_in_dim=4,
    node_hidden_dim=32,
    gru_hidden_dim=64,
    num_turbines=num_turbines
).to(device)
yaw_optimizer.load_state_dict(torch.load("tgn_yaw_optimizer.pth"))
yaw_optimizer.eval()

surrogate.eval()

# Pick the latest available wind sequence
new_sequence = temporal_sequences[-1]

with torch.no_grad():
    predicted_yaws = yaw_optimizer([new_sequence])
    predicted_yaws = predicted_yaws.squeeze(0).cpu().numpy()

# Simulate optimised yaw angles using PyWake with real flow model
site = UniformSite(p_wd=[1], ti=0.1)
site.default_wd = np.mean(wind_direction[-1].numpy())  # timestep 45 wind dir
site.default_ws = np.mean(wind_speed[-1].numpy())      # timestep 45 wind speed

wake_model = Bastankhah_PorteAgel_2014(site, V80(), k=0.075, superpositionModel=SquaredSum())
sim_res = wake_model(turbine_x.numpy(), turbine_y.numpy(), yaw=predicted_yaws)

# Plot optimised yaw layout and power output
fig, axs = plt.subplots(1, 2, figsize=(14, 6))

sim_res.flow_map().plot_wake_map(ax=axs[0])
axs[0].scatter(turbine_x, turbine_y, color='black', zorder=3)

yaw_rad = np.deg2rad(predicted_yaws)
for xi, yi, yaw in zip(turbine_x, turbine_y, yaw_rad):
    axs[0].plot([xi, xi + 150 * np.cos(yaw)], [yi, yi + 150 * np.sin(yaw)], color='black', linewidth=1)

axs[0].set_title("Optimized Yaw Layout (TGN)")

power_output = sim_res.Power.values.flatten()
scatter = axs[1].scatter(turbine_x, turbine_y, c=power_output, cmap='Blues', s=50)
axs[1].set_title("Power Output (Optimized Yaw)")
fig.colorbar(scatter, ax=axs[1], label='Power (MW)')

plt.tight_layout()
plt.show()

# Calculate total power output after optimization
total_power_MW = np.sum(sim_res.Power.values) / 1e6
print(f"FINAL Optimized Power Output (PyWake): {total_power_MW:.2f} MW")